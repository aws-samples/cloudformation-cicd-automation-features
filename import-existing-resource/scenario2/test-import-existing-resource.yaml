AWSTemplateFormatVersion: '2010-09-09'
Description: This CloudFormation template is used to display the import-existing-resource feature of CloudFormation.

Parameters:
  DynamoDBTableName:
    Type: String
    Description: Name of the DynamoDB table.
    
  LambdaFunctionName:
    Type: String
    Description: Name of the Lambda function.

  S3BucketName:
    Type: String
    Description: Name of the S3 Bucket to import.
    
Resources:
  DynamoDBTable:
    Type: 'AWS::DynamoDB::Table'
    DeletionPolicy: Retain
    UpdateReplacePolicy: Delete
    Properties:
      TableName: !Ref DynamoDBTableName
      PointInTimeRecoverySpecification: 
        PointInTimeRecoveryEnabled: true
      AttributeDefinitions:
        - AttributeName: PK
          AttributeType: S
      KeySchema:
        - AttributeName: PK
          KeyType: HASH
      BillingMode: PAY_PER_REQUEST
      
  LambdaFunction:
    Type: 'AWS::Lambda::Function'
    DeletionPolicy: Retain
    UpdateReplacePolicy: Delete
    Properties:
      FunctionName: !Ref LambdaFunctionName
      Handler: index.lambda_handler
      Role: !GetAtt [ LambdaExecutionRole, Arn ]
      Runtime: python3.8
      Code:
        ZipFile: |
            import boto3
            import os
            import urllib.parse
            import json

            def lambda_handler(event, context):
                try:
                    s3 = boto3.resource('s3')
                    print(event)
                    dynamodb = boto3.resource('dynamodb')
                    table = dynamodb.Table(os.environ['DYNAMODB_TABLE'])        
                    for record in event['Records']:
                        bucket = record['s3']['bucket']['name']
                        key = urllib.parse.unquote_plus(record['s3']['object']['key'])
                        eTag = record['s3']['object']['eTag']
                        print(key)
                        item = {
                            'PK': key,  # Assuming the S3 object key is unique and can be used as the DynamoDB primary key
                            'Bucket': bucket,
                            'eTag': eTag
                        }
                        table.put_item(Item=item)
                    return event

                except Exception as e:
                    print(e)
                    return None

      Environment:
        Variables:
          DYNAMODB_TABLE: !Ref DynamoDBTableName
     
  LambdaExecutionRole:
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName: 'custom-lambda-execution-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      ManagedPolicyArns:
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/AmazonDynamoDBFullAccess"
        - !Sub "arn:${AWS::Partition}:iam::aws:policy/AmazonS3ReadOnlyAccess"

  LambdaFunctionPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !Ref LambdaFunctionName
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !GetAtt S3Bucket.Arn
      
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Retain
    UpdateReplacePolicy: Delete
    Properties:
      BucketName: !Ref S3BucketName
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: s3:ObjectRemoved:*
            Function: !GetAtt LambdaFunction.Arn
      
Outputs: 

  DynamoDBTableARN: 
    Description: DynamoDB table's ARN
    Value: !GetAtt DynamoDBTable.Arn
    
  LambdaFunctionARN: 
    Description: Lambda function's ARN
    Value: !GetAtt LambdaFunction.Arn